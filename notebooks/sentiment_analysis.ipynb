{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac98302e",
   "metadata": {},
   "source": [
    "## Sentiment Analysis\n",
    "\n",
    "Apply FinBERT and VADER sentiment analysis to the cleaned headlines and merge with stock prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76231d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from: d:\\Financial News Sentiment Analysis\\Data\\merged_news_prices_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "NOTEBOOK_DIR = Path.cwd()\n",
    "ROOT = NOTEBOOK_DIR.parent if NOTEBOOK_DIR.name == \"notebooks\" else NOTEBOOK_DIR\n",
    "DATA_DIR = ROOT / \"Data\"\n",
    "MERGED_PATH = DATA_DIR / \"merged_news_prices_cleaned.csv\"\n",
    "OUTPUT_PATH = DATA_DIR / \"final_sentiment_dataset.csv\"\n",
    "\n",
    "print(f\"Loading data from: {MERGED_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0cfa09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 81 rows\n",
      "\n",
      "Columns: ['Date', 'Ticker', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'Headlines', 'Target', 'Headlines_clean']\n",
      "\n",
      "Sample data:\n",
      "        Date Ticker                                          Headlines  \\\n",
      "0 2020-06-09   AAPL  Why Apple's Stock Is Trading Higher Today Appl...   \n",
      "1 2020-06-09   AMZN  'Inside Amazon's plan to test warehouse worker...   \n",
      "2 2011-05-23    DNO      American Drivers Should Thank European Voters   \n",
      "3 2011-06-08    DNO                                   The End of OPEC?   \n",
      "4 2011-07-01    DNO  Is China's Slowdown Bullish for the Global Eco...   \n",
      "\n",
      "                                     Headlines_clean  \n",
      "0  apple stock trading higher today apple could a...  \n",
      "1  inside amazon plan test warehouse worker covid...  \n",
      "2               american driver thank european voter  \n",
      "3                                           end opec  \n",
      "4              china slowdown bullish global economy  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv(MERGED_PATH, parse_dates=[\"Date\"])\n",
    "\n",
    "\n",
    "print(f\"Loaded {len(df)} rows\")\n",
    "print(f\"\\nColumns: {df.columns.tolist()}\")\n",
    "print(f\"\\nSample data:\")\n",
    "print(df[[\"Date\", \"Ticker\", \"Headlines\", \"Headlines_clean\"]].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03574735",
   "metadata": {},
   "source": [
    "### FinBERT Sentiment Analysis\n",
    "\n",
    "Load ProsusAI/finbert model and extract softmax probabilities for positive, negative, and neutral sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfef50d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ProsusAI/finbert...\n",
      "Model loaded on cpu\n",
      "Label mapping: {0: 'positive', 1: 'negative', 2: 'neutral'}\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from torch.nn.functional import softmax\n",
    "\n",
    "\n",
    "model_name = \"ProsusAI/finbert\"\n",
    "print(f\"Loading {model_name}...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(f\"Model loaded on {device}\")\n",
    "print(f\"Label mapping: {model.config.id2label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca37864f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FinBERT sentiment function defined\n"
     ]
    }
   ],
   "source": [
    "def get_finbert_sentiment(text: str, max_length: int = 512) -> dict:\n",
    "    \"\"\"\n",
    "    Get FinBERT sentiment scores for a text.\n",
    "    Returns dict with positive, negative, neutral probabilities.\n",
    "    \"\"\"\n",
    "    if not text or not isinstance(text, str):\n",
    "        return {\"finbert_pos\": 0.0, \"finbert_neg\": 0.0, \"finbert_neutral\": 0.0}\n",
    "    \n",
    "    \n",
    "    if len(text.split()) > max_length:\n",
    "        text = \" \".join(text.split()[:max_length])\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, \n",
    "                          max_length=512, padding=True).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            probs = softmax(outputs.logits, dim=1)[0]\n",
    "        \n",
    "        \n",
    "        scores = {}\n",
    "        for idx, prob in enumerate(probs.cpu().numpy()):\n",
    "            label = model.config.id2label[idx].lower()\n",
    "            scores[f\"finbert_{label}\"] = float(prob)\n",
    "        \n",
    "        return scores\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing text: {str(e)[:100]}\")\n",
    "        return {\"finbert_pos\": 0.0, \"finbert_neg\": 0.0, \"finbert_neutral\": 0.0}\n",
    "\n",
    "print(\"FinBERT sentiment function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08bab27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying FinBERT sentiment analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FinBERT: 100%|██████████| 81/81 [00:08<00:00,  9.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FinBERT scores added:\n",
      "                                     Headlines_clean  finbert_positive  \\\n",
      "0  apple stock trading higher today apple could a...          0.921895   \n",
      "1  inside amazon plan test warehouse worker covid...          0.802511   \n",
      "2               american driver thank european voter          0.111590   \n",
      "3                                           end opec          0.057174   \n",
      "4              china slowdown bullish global economy          0.081749   \n",
      "\n",
      "   finbert_negative  finbert_neutral  \n",
      "0          0.028169         0.049936  \n",
      "1          0.141895         0.055594  \n",
      "2          0.055815         0.832595  \n",
      "3          0.124650         0.818175  \n",
      "4          0.269374         0.648877  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Apply FinBERT to cleaned headlines\n",
    "print(\"Applying FinBERT sentiment analysis...\")\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "finbert_scores = [get_finbert_sentiment(text) for text in tqdm(df[\"Headlines_clean\"], desc=\"FinBERT\")]\n",
    "finbert_df = pd.DataFrame(finbert_scores)\n",
    "\n",
    "\n",
    "df = pd.concat([df, finbert_df], axis=1)\n",
    "\n",
    "print(f\"\\nFinBERT scores added:\")\n",
    "print(df[[\"Headlines_clean\", \"finbert_positive\", \"finbert_negative\", \"finbert_neutral\"]].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11da90d6",
   "metadata": {},
   "source": [
    "### VADER Sentiment Analysis\n",
    "\n",
    "Apply VADER (Valence Aware Dictionary and sEntiment Reasoner) as a baseline and extract the compound score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9332c773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VADER analyzer initialized\n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "\n",
    "nltk.download('vader_lexicon', quiet=True)\n",
    "\n",
    "\n",
    "vader = SentimentIntensityAnalyzer()\n",
    "\n",
    "def get_vader_compound(text: str) -> float:\n",
    "    \"\"\"Get VADER compound sentiment score.\"\"\"\n",
    "    if not text or not isinstance(text, str):\n",
    "        return 0.0\n",
    "    try:\n",
    "        scores = vader.polarity_scores(text)\n",
    "        return scores['compound']\n",
    "    except:\n",
    "        return 0.0\n",
    "\n",
    "print(\"VADER analyzer initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03eaad5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying VADER sentiment analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VADER: 100%|██████████| 81/81 [00:00<00:00, 2180.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "VADER scores added:\n",
      "                                     Headlines_clean  vader_compound\n",
      "0  apple stock trading higher today apple could a...          0.7530\n",
      "1  inside amazon plan test warehouse worker covid...          0.3252\n",
      "2               american driver thank european voter          0.3612\n",
      "3                                           end opec          0.0000\n",
      "4              china slowdown bullish global economy          0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Apply VADER to cleaned headlines\n",
    "print(\"Applying VADER sentiment analysis...\")\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "vader_scores = [get_vader_compound(text) for text in tqdm(df[\"Headlines_clean\"], desc=\"VADER\")]\n",
    "df[\"vader_compound\"] = vader_scores\n",
    "\n",
    "print(f\"\\nVADER scores added:\")\n",
    "print(df[[\"Headlines_clean\", \"vader_compound\"]].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e2ee6a",
   "metadata": {},
   "source": [
    "### Add Technical Indicators\n",
    "\n",
    "Calculate common technical indicators from price data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7cc875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating technical indicators per ticker...\n",
      "\n",
      "Technical indicators added\n",
      "New columns: ['SMA_5', 'EMA_12', 'MACD', 'RSI', 'Price_change']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = df.sort_values([\"Ticker\", \"Date\"]).reset_index(drop=True)\n",
    "\n",
    "\n",
    "def add_technical_indicators(group):\n",
    "    \"\"\"Add technical indicators for a single stock.\"\"\"\n",
    "    # Simple Moving Averages\n",
    "    group[\"SMA_5\"] = group[\"Close\"].rolling(window=5, min_periods=1).mean()\n",
    "    group[\"SMA_10\"] = group[\"Close\"].rolling(window=10, min_periods=1).mean()\n",
    "    group[\"SMA_20\"] = group[\"Close\"].rolling(window=20, min_periods=1).mean()\n",
    "    \n",
    "    # Exponential Moving Average\n",
    "    group[\"EMA_12\"] = group[\"Close\"].ewm(span=12, adjust=False).mean()\n",
    "    group[\"EMA_26\"] = group[\"Close\"].ewm(span=26, adjust=False).mean()\n",
    "    \n",
    "    # MACD\n",
    "    group[\"MACD\"] = group[\"EMA_12\"] - group[\"EMA_26\"]\n",
    "    group[\"MACD_signal\"] = group[\"MACD\"].ewm(span=9, adjust=False).mean()\n",
    "    \n",
    "    # RSI (Relative Strength Index)\n",
    "    delta = group[\"Close\"].diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=14, min_periods=1).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=14, min_periods=1).mean()\n",
    "    rs = gain / loss\n",
    "    group[\"RSI\"] = 100 - (100 / (1 + rs))\n",
    "    \n",
    "    # Bollinger Bands\n",
    "    group[\"BB_middle\"] = group[\"Close\"].rolling(window=20, min_periods=1).mean()\n",
    "    bb_std = group[\"Close\"].rolling(window=20, min_periods=1).std()\n",
    "    group[\"BB_upper\"] = group[\"BB_middle\"] + (2 * bb_std)\n",
    "    group[\"BB_lower\"] = group[\"BB_middle\"] - (2 * bb_std)\n",
    "    \n",
    "    # Price momentum\n",
    "    group[\"Price_change\"] = group[\"Close\"].pct_change()\n",
    "    group[\"Price_change_5d\"] = group[\"Close\"].pct_change(periods=5)\n",
    "    \n",
    "    return group\n",
    "\n",
    "print(\"Calculating technical indicators per ticker...\")\n",
    "df = df.groupby(\"Ticker\", group_keys=False).apply(add_technical_indicators)\n",
    "\n",
    "print(\"\\nTechnical indicators added\")\n",
    "print(f\"New columns: {[c for c in df.columns if c in ['SMA_5', 'EMA_12', 'MACD', 'RSI', 'Price_change']]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05ace43",
   "metadata": {},
   "source": [
    "### Final Dataset\n",
    "\n",
    "Prepare the final dataset with all features and save to CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2941b1b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "FINAL DATASET SUMMARY\n",
      "================================================================================\n",
      "\n",
      "Total rows: 81\n",
      "Date range: 2011-04-29 00:00:00 to 2020-06-09 00:00:00\n",
      "Tickers: []\n",
      "\n",
      "Columns (27):\n",
      "  - Date\n",
      "  - Open\n",
      "  - High\n",
      "  - Low\n",
      "  - Close\n",
      "  - Adj Close\n",
      "  - Volume\n",
      "  - Headlines\n",
      "  - Target\n",
      "  - Headlines_clean\n",
      "  - finbert_positive\n",
      "  - finbert_negative\n",
      "  - finbert_neutral\n",
      "  - vader_compound\n",
      "  - SMA_5\n",
      "  - SMA_10\n",
      "  - SMA_20\n",
      "  - EMA_12\n",
      "  - EMA_26\n",
      "  - MACD\n",
      "  - MACD_signal\n",
      "  - RSI\n",
      "  - BB_middle\n",
      "  - BB_upper\n",
      "  - BB_lower\n",
      "  - Price_change\n",
      "  - Price_change_5d\n",
      "\n",
      "================================================================================\n",
      "SAMPLE DATA\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Headlines</th>\n",
       "      <th>Target</th>\n",
       "      <th>Headlines_clean</th>\n",
       "      <th>...</th>\n",
       "      <th>EMA_12</th>\n",
       "      <th>EMA_26</th>\n",
       "      <th>MACD</th>\n",
       "      <th>MACD_signal</th>\n",
       "      <th>RSI</th>\n",
       "      <th>BB_middle</th>\n",
       "      <th>BB_upper</th>\n",
       "      <th>BB_lower</th>\n",
       "      <th>Price_change</th>\n",
       "      <th>Price_change_5d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-06-09</td>\n",
       "      <td>83.035004</td>\n",
       "      <td>86.402496</td>\n",
       "      <td>83.002502</td>\n",
       "      <td>85.997498</td>\n",
       "      <td>83.889359</td>\n",
       "      <td>147712400</td>\n",
       "      <td>Why Apple's Stock Is Trading Higher Today Appl...</td>\n",
       "      <td>1</td>\n",
       "      <td>apple stock trading higher today apple could a...</td>\n",
       "      <td>...</td>\n",
       "      <td>85.997498</td>\n",
       "      <td>85.997498</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85.997498</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-06-09</td>\n",
       "      <td>126.472000</td>\n",
       "      <td>131.321503</td>\n",
       "      <td>126.250000</td>\n",
       "      <td>130.042999</td>\n",
       "      <td>130.042999</td>\n",
       "      <td>103520000</td>\n",
       "      <td>'Inside Amazon's plan to test warehouse worker...</td>\n",
       "      <td>1</td>\n",
       "      <td>inside amazon plan test warehouse worker covid...</td>\n",
       "      <td>...</td>\n",
       "      <td>130.042999</td>\n",
       "      <td>130.042999</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>130.042999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-05-23</td>\n",
       "      <td>38.970001</td>\n",
       "      <td>39.090000</td>\n",
       "      <td>38.700001</td>\n",
       "      <td>38.779999</td>\n",
       "      <td>38.779999</td>\n",
       "      <td>13400</td>\n",
       "      <td>American Drivers Should Thank European Voters</td>\n",
       "      <td>0</td>\n",
       "      <td>american driver thank european voter</td>\n",
       "      <td>...</td>\n",
       "      <td>38.779999</td>\n",
       "      <td>38.779999</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.779999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-06-08</td>\n",
       "      <td>37.889999</td>\n",
       "      <td>37.889999</td>\n",
       "      <td>37.040001</td>\n",
       "      <td>37.389999</td>\n",
       "      <td>37.389999</td>\n",
       "      <td>38900</td>\n",
       "      <td>The End of OPEC?</td>\n",
       "      <td>1</td>\n",
       "      <td>end opec</td>\n",
       "      <td>...</td>\n",
       "      <td>38.566153</td>\n",
       "      <td>38.677036</td>\n",
       "      <td>-0.110883</td>\n",
       "      <td>-0.022177</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38.084999</td>\n",
       "      <td>40.050755</td>\n",
       "      <td>36.119243</td>\n",
       "      <td>-0.035843</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-07-01</td>\n",
       "      <td>39.889999</td>\n",
       "      <td>40.160000</td>\n",
       "      <td>39.459999</td>\n",
       "      <td>39.650002</td>\n",
       "      <td>39.650002</td>\n",
       "      <td>9100</td>\n",
       "      <td>Is China's Slowdown Bullish for the Global Eco...</td>\n",
       "      <td>1</td>\n",
       "      <td>china slowdown bullish global economy</td>\n",
       "      <td>...</td>\n",
       "      <td>38.732899</td>\n",
       "      <td>38.749107</td>\n",
       "      <td>-0.016209</td>\n",
       "      <td>-0.020983</td>\n",
       "      <td>61.917841</td>\n",
       "      <td>38.606667</td>\n",
       "      <td>40.886522</td>\n",
       "      <td>36.326811</td>\n",
       "      <td>0.060444</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date        Open        High         Low       Close   Adj Close  \\\n",
       "0 2020-06-09   83.035004   86.402496   83.002502   85.997498   83.889359   \n",
       "1 2020-06-09  126.472000  131.321503  126.250000  130.042999  130.042999   \n",
       "2 2011-05-23   38.970001   39.090000   38.700001   38.779999   38.779999   \n",
       "3 2011-06-08   37.889999   37.889999   37.040001   37.389999   37.389999   \n",
       "4 2011-07-01   39.889999   40.160000   39.459999   39.650002   39.650002   \n",
       "\n",
       "      Volume                                          Headlines  Target  \\\n",
       "0  147712400  Why Apple's Stock Is Trading Higher Today Appl...       1   \n",
       "1  103520000  'Inside Amazon's plan to test warehouse worker...       1   \n",
       "2      13400      American Drivers Should Thank European Voters       0   \n",
       "3      38900                                   The End of OPEC?       1   \n",
       "4       9100  Is China's Slowdown Bullish for the Global Eco...       1   \n",
       "\n",
       "                                     Headlines_clean  ...      EMA_12  \\\n",
       "0  apple stock trading higher today apple could a...  ...   85.997498   \n",
       "1  inside amazon plan test warehouse worker covid...  ...  130.042999   \n",
       "2               american driver thank european voter  ...   38.779999   \n",
       "3                                           end opec  ...   38.566153   \n",
       "4              china slowdown bullish global economy  ...   38.732899   \n",
       "\n",
       "       EMA_26      MACD  MACD_signal        RSI   BB_middle   BB_upper  \\\n",
       "0   85.997498  0.000000     0.000000        NaN   85.997498        NaN   \n",
       "1  130.042999  0.000000     0.000000        NaN  130.042999        NaN   \n",
       "2   38.779999  0.000000     0.000000        NaN   38.779999        NaN   \n",
       "3   38.677036 -0.110883    -0.022177   0.000000   38.084999  40.050755   \n",
       "4   38.749107 -0.016209    -0.020983  61.917841   38.606667  40.886522   \n",
       "\n",
       "    BB_lower  Price_change  Price_change_5d  \n",
       "0        NaN           NaN              NaN  \n",
       "1        NaN           NaN              NaN  \n",
       "2        NaN           NaN              NaN  \n",
       "3  36.119243     -0.035843              NaN  \n",
       "4  36.326811      0.060444              NaN  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SENTIMENT SCORES SUMMARY\n",
      "================================================================================\n",
      "       finbert_positive  finbert_negative  finbert_neutral  vader_compound\n",
      "count         81.000000         81.000000        81.000000       81.000000\n",
      "mean           0.182858          0.157338         0.659804        0.111511\n",
      "std            0.247465          0.263878         0.328735        0.319905\n",
      "min            0.011334          0.009634         0.018366       -0.954500\n",
      "25%            0.045680          0.019426         0.483798        0.000000\n",
      "50%            0.081042          0.034265         0.829882        0.000000\n",
      "75%            0.158642          0.153841         0.914034        0.340000\n",
      "max            0.946143          0.954340         0.940571        0.886000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"FINAL DATASET SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nTotal rows: {len(df)}\")\n",
    "print(f\"Date range: {df['Date'].min()} to {df['Date'].max()}\")\n",
    "\n",
    "ticker_list = sorted(df['Ticker'].unique()) if 'Ticker' in df.columns else []\n",
    "print(f\"Tickers: {ticker_list}\")\n",
    "print(f\"\\nColumns ({len(df.columns)}):\")\n",
    "for col in df.columns:\n",
    "    print(f\"  - {col}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SAMPLE DATA\")\n",
    "print(\"=\" * 80)\n",
    "display(df.head())\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SENTIMENT SCORES SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "sentiment_cols = [c for c in [\"finbert_positive\", \"finbert_negative\", \"finbert_neutral\", \"vader_compound\"] if c in df.columns]\n",
    "print(df[sentiment_cols].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56d31deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final dataset saved to: c:\\Users\\hp\\Desktop\\NLP course\\Financial News Sentiment Analysis\\Data\\final_sentiment_dataset.csv\n",
      "File size: 43.02 KB\n"
     ]
    }
   ],
   "source": [
    "# Save final dataset\n",
    "df.to_csv(OUTPUT_PATH, index=False)\n",
    "print(f\"\\nFinal dataset saved to: {OUTPUT_PATH}\")\n",
    "print(f\"File size: {OUTPUT_PATH.stat().st_size / 1024:.2f} KB\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
