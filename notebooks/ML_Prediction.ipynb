{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f99fe1ef",
   "metadata": {},
   "source": [
    "## Machine learing Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "866fa973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 81 rows from d:\\Financial News Sentiment Analysis\\Data\\final_sentiment_dataset.csv\n",
      "        Date        Open        High         Low       Close   Adj Close  \\\n",
      "0 2020-06-09   83.035004   86.402496   83.002502   85.997498   83.889359   \n",
      "1 2020-06-09  126.472000  131.321503  126.250000  130.042999  130.042999   \n",
      "2 2011-05-23   38.970001   39.090000   38.700001   38.779999   38.779999   \n",
      "3 2011-06-08   37.889999   37.889999   37.040001   37.389999   37.389999   \n",
      "4 2011-07-01   39.889999   40.160000   39.459999   39.650002   39.650002   \n",
      "\n",
      "      Volume                                          Headlines  Target  \\\n",
      "0  147712400  Why Apple's Stock Is Trading Higher Today Appl...       1   \n",
      "1  103520000  'Inside Amazon's plan to test warehouse worker...       1   \n",
      "2      13400      American Drivers Should Thank European Voters       0   \n",
      "3      38900                                   The End of OPEC?       1   \n",
      "4       9100  Is China's Slowdown Bullish for the Global Eco...       1   \n",
      "\n",
      "                                     Headlines_clean  ...      EMA_12  \\\n",
      "0  apple stock trading higher today apple could a...  ...   85.997498   \n",
      "1  inside amazon plan test warehouse worker covid...  ...  130.042999   \n",
      "2               american driver thank european voter  ...   38.779999   \n",
      "3                                           end opec  ...   38.566153   \n",
      "4              china slowdown bullish global economy  ...   38.732899   \n",
      "\n",
      "       EMA_26      MACD  MACD_signal        RSI   BB_middle   BB_upper  \\\n",
      "0   85.997498  0.000000     0.000000        NaN   85.997498        NaN   \n",
      "1  130.042999  0.000000     0.000000        NaN  130.042999        NaN   \n",
      "2   38.779999  0.000000     0.000000        NaN   38.779999        NaN   \n",
      "3   38.677036 -0.110883    -0.022177   0.000000   38.084999  40.050755   \n",
      "4   38.749107 -0.016209    -0.020983  61.917841   38.606667  40.886522   \n",
      "\n",
      "    BB_lower  Price_change  Price_change_5d  \n",
      "0        NaN           NaN              NaN  \n",
      "1        NaN           NaN              NaN  \n",
      "2        NaN           NaN              NaN  \n",
      "3  36.119243     -0.035843              NaN  \n",
      "4  36.326811      0.060444              NaN  \n",
      "\n",
      "[5 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Paths\n",
    "NOTEBOOK_DIR = Path.cwd()\n",
    "ROOT = NOTEBOOK_DIR.parent if NOTEBOOK_DIR.name == \"notebooks\" else NOTEBOOK_DIR\n",
    "DATA_DIR = ROOT / \"Data\"\n",
    "DATA_PATH = DATA_DIR / \"final_sentiment_dataset.csv\"\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(DATA_PATH, parse_dates=[\"Date\"])\n",
    "print(f\"Loaded {len(df)} rows from {DATA_PATH}\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd42c32b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Info: 'Ticker' missing; filled with single label 'TCKR'.\n",
      "Feature columns used: ['finbert_positive', 'finbert_negative', 'finbert_neutral', 'vader_compound', 'Open', 'High', 'Low', 'Close', 'Volume', 'SMA_5']\n",
      "X shape: (81, 10) y shape: (81,)\n",
      "Class distribution:\n",
      " Target\n",
      "1    50\n",
      "0    31\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Feature selection and preprocessing\n",
    "feature_cols = [\n",
    "    \"finbert_positive\", \"finbert_negative\", \"finbert_neutral\",\n",
    "    \"vader_compound\", \"Open\", \"High\", \"Low\", \"Close\", \"Volume\", \"SMA_5\"\n",
    "]\n",
    "\n",
    "# If Ticker missing, create a single ticker label to allow grouping\n",
    "df = df.copy()\n",
    "if \"Ticker\" not in df.columns:\n",
    "    df[\"Ticker\"] = \"TCKR\"\n",
    "    print(\"Info: 'Ticker' missing; filled with single label 'TCKR'.\")\n",
    "\n",
    "# Ensure SMA_5 exists; compute if missing\n",
    "if \"SMA_5\" not in df.columns:\n",
    "    df = df.sort_values([\"Ticker\", \"Date\"]).reset_index(drop=True)\n",
    "    df[\"SMA_5\"] = df.groupby(\"Ticker\")['Close'].transform(lambda s: s.rolling(5, min_periods=1).mean())\n",
    "\n",
    "# Determine available columns\n",
    "available_features = [c for c in feature_cols if c in df.columns]\n",
    "required_cols = available_features + [c for c in [\"Target\", \"Ticker\", \"Date\"] if c in df.columns]\n",
    "missing_required = [c for c in [\"Target\", \"Ticker\", \"Date\"] if c not in df.columns]\n",
    "if missing_required:\n",
    "    print(\"Warning: missing required columns, rows may be incomplete:\", missing_required)\n",
    "\n",
    "if \"Target\" not in df.columns:\n",
    "    raise ValueError(\"Target column missing; rebuild dataset to include 'Target'.\")\n",
    "\n",
    "# Drop rows with missing available features/target\n",
    "if required_cols:\n",
    "    df = df.dropna(subset=required_cols).reset_index(drop=True)\n",
    "else:\n",
    "    raise ValueError(\"No required columns available to proceed.\")\n",
    "\n",
    "X = df[available_features]\n",
    "y = df[\"Target\"].astype(int)\n",
    "\n",
    "print(\"Feature columns used:\", available_features)\n",
    "print(\"X shape:\", X.shape, \"y shape:\", y.shape)\n",
    "print(\"Class distribution:\\n\", y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69f69fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.47058823529411764\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.000     0.000     0.000         7\n",
      "           1      0.533     0.800     0.640        10\n",
      "\n",
      "    accuracy                          0.471        17\n",
      "   macro avg      0.267     0.400     0.320        17\n",
      "weighted avg      0.314     0.471     0.376        17\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest classifier\n",
    "class_counts = y.value_counts()\n",
    "min_class = class_counts.min()\n",
    "use_stratify = min_class >= 2\n",
    "if not use_stratify:\n",
    "    print(\"Note: Not enough samples per class for stratified split; using simple split without stratify.\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2 if len(y) > 4 else 0.33,\n",
    "    shuffle=True,\n",
    "    stratify=y if use_stratify else None,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=None,\n",
    "    min_samples_leaf=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification report:\\n\", classification_report(y_test, y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6014aa85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved RandomForest model to d:\\Financial News Sentiment Analysis\\ml\\serving\\model.joblib\n"
     ]
    }
   ],
   "source": [
    "# Save Random Forest model and feature names\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "out_dir = ROOT / \"ml\" / \"serving\"\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "rf_path = out_dir / \"model.joblib\"\n",
    "# ensure feature names stored (sklearn may expect feature_names_in_)\n",
    "try:\n",
    "    rf.feature_names_in_ = np.array(available_features)\n",
    "except Exception:\n",
    "    pass\n",
    "joblib.dump(rf, rf_path)\n",
    "print(f\"Saved RandomForest model to {rf_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e009e934",
   "metadata": {},
   "source": [
    "### LSTM sequence model\n",
    "\n",
    "Sequence last 7 days of features to predict the next day (day 8)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f0d7fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence shapes:\n",
      "X_train_seq: (58, 7, 10) y_train_seq: (58,)\n",
      "X_test_seq: (16, 7, 10) y_test_seq: (16,)\n",
      "Epoch 1/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 226ms/step - accuracy: 0.4565 - loss: 0.6999 - val_accuracy: 0.5833 - val_loss: 0.6922\n",
      "Epoch 2/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.5217 - loss: 0.6932 - val_accuracy: 0.5833 - val_loss: 0.6917\n",
      "Epoch 3/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.5217 - loss: 0.6927 - val_accuracy: 0.5833 - val_loss: 0.6918\n",
      "Epoch 4/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.6304 - loss: 0.6829 - val_accuracy: 0.5833 - val_loss: 0.6927\n",
      "Epoch 5/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.6087 - loss: 0.6738 - val_accuracy: 0.5833 - val_loss: 0.6934\n",
      "Epoch 6/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.5652 - loss: 0.6800 - val_accuracy: 0.5833 - val_loss: 0.6945\n",
      "Epoch 7/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.6087 - loss: 0.6826 - val_accuracy: 0.5833 - val_loss: 0.6962\n",
      "Epoch 8/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.5870 - loss: 0.6803 - val_accuracy: 0.5833 - val_loss: 0.6978\n",
      "Epoch 9/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5870 - loss: 0.6701 - val_accuracy: 0.5833 - val_loss: 0.6996\n",
      "Epoch 10/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.5870 - loss: 0.6665 - val_accuracy: 0.5833 - val_loss: 0.7016\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332ms/step\n",
      "\n",
      "LSTM Accuracy: 0.750\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.000     0.000     0.000         4\n",
      "           1      0.750     1.000     0.857        12\n",
      "\n",
      "    accuracy                          0.750        16\n",
      "   macro avg      0.375     0.500     0.429        16\n",
      "weighted avg      0.562     0.750     0.643        16\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Financial News Sentiment Analysis\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "d:\\Financial News Sentiment Analysis\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "d:\\Financial News Sentiment Analysis\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "SEQ_LEN = 7\n",
    "lstm_features = available_features\n",
    "\n",
    "if len(lstm_features) == 0:\n",
    "    raise ValueError(\"No feature columns available for LSTM.\")\n",
    "\n",
    "# Sort by ticker/date\n",
    "seq_df = df.sort_values([\"Ticker\", \"Date\"]).reset_index(drop=True)\n",
    "\n",
    "# Fit scaler on training portion (per-ticker split)\n",
    "scaler = StandardScaler()\n",
    "train_mask = pd.Series(False, index=seq_df.index)\n",
    "for _, g in seq_df.groupby(\"Ticker\"):\n",
    "    split_idx = int(len(g) * 0.8)\n",
    "    train_mask.loc[g.index[:split_idx]] = True\n",
    "scaler.fit(seq_df.loc[train_mask, lstm_features])\n",
    "\n",
    "seq_df_scaled = seq_df.copy()\n",
    "seq_df_scaled[lstm_features] = scaler.transform(seq_df_scaled[lstm_features])\n",
    "\n",
    "\n",
    "def build_sequences_split(dataframe, feature_cols, target_col, seq_len=7, split_ratio=0.8):\n",
    "    X_train, y_train, X_test, y_test = [], [], [], []\n",
    "    for _, g in dataframe.groupby(\"Ticker\"):\n",
    "        g = g.sort_values(\"Date\").reset_index(drop=True)\n",
    "        if len(g) <= seq_len:\n",
    "            continue  # not enough rows to form one sequence\n",
    "        feats = g[feature_cols].values\n",
    "        target = g[target_col].values\n",
    "        split_idx = int(len(g) * split_ratio)\n",
    "        for i in range(len(g) - seq_len):\n",
    "            end_idx = i + seq_len\n",
    "            X_seq = feats[i:end_idx]\n",
    "            y_val = target[end_idx]\n",
    "            if end_idx <= split_idx:\n",
    "                X_train.append(X_seq)\n",
    "                y_train.append(y_val)\n",
    "            else:\n",
    "                X_test.append(X_seq)\n",
    "                y_test.append(y_val)\n",
    "    return np.array(X_train), np.array(y_train), np.array(X_test), np.array(y_test)\n",
    "\n",
    "X_train_seq, y_train_seq, X_test_seq, y_test_seq = build_sequences_split(\n",
    "    seq_df_scaled, lstm_features, \"Target\", seq_len=SEQ_LEN, split_ratio=0.8\n",
    ")\n",
    "\n",
    "print(\"Sequence shapes:\")\n",
    "print(\"X_train_seq:\", X_train_seq.shape, \"y_train_seq:\", y_train_seq.shape)\n",
    "print(\"X_test_seq:\", X_test_seq.shape, \"y_test_seq:\", y_test_seq.shape)\n",
    "\n",
    "if len(X_train_seq) == 0 or len(X_test_seq) == 0:\n",
    "    raise ValueError(\"Not enough sequence data for LSTM; need more rows per ticker.\")\n",
    "\n",
    "# Build LSTM model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(SEQ_LEN, len(lstm_features))),\n",
    "    tf.keras.layers.LSTM(32, return_sequences=False),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(16, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "])\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_seq, y_train_seq,\n",
    "    validation_split=0.2,\n",
    "    epochs=10,\n",
    "    batch_size=16,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "y_pred_prob = model.predict(X_test_seq)\n",
    "y_pred_label = (y_pred_prob.flatten() >= 0.5).astype(int)\n",
    "\n",
    "lstm_acc = accuracy_score(y_test_seq, y_pred_label)\n",
    "print(f\"\\nLSTM Accuracy: {lstm_acc:.3f}\")\n",
    "print(\"\\nClassification report:\\n\", classification_report(y_test_seq, y_pred_label, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fc317c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved LSTM model to d:\\Financial News Sentiment Analysis\\ml\\serving\\lstm_model.keras and preprocessing to d:\\Financial News Sentiment Analysis\\ml\\serving\\lstm_prep.joblib\n"
     ]
    }
   ],
   "source": [
    "# Save LSTM model and preprocessing artifacts\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "\n",
    "out_dir = ROOT / \"ml\" / \"serving\"\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "lstm_path = out_dir / \"lstm_model.keras\"\n",
    "# Save Keras model in Keras native format\n",
    "model.save(lstm_path, save_format=\"keras\")\n",
    "\n",
    "prep_path = out_dir / \"lstm_prep.joblib\"\n",
    "try:\n",
    "    joblib.dump({\"scaler\": scaler, \"features\": lstm_features}, prep_path)\n",
    "    print(f\"Saved LSTM model to {lstm_path} and preprocessing to {prep_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Saved LSTM model to {lstm_path} but failed to save preprocessing: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
